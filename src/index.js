import express from "express";
import cors from "cors";
import "dotenv/config";
import OpenAI from "openai";

import { getUserFromAuthHeader } from "./auth.js";
import { loadUserVotes } from "./analysis.js";
import { buildPrompt } from "./prompt.js";

const app = express();
app.use(cors());
app.use(express.json());

// ---- basic env validation ----
const PORT = Number(process.env.PORT || 4000);

if (!process.env.OPENAI_API_KEY) {
  console.error("Missing OPENAI_API_KEY in .env");
  process.exit(1);
}
if (!process.env.SUPABASE_URL) {
  console.error("Missing SUPABASE_URL in .env");
  process.exit(1);
}
if (!process.env.SUPABASE_SERVICE_ROLE_KEY) {
  console.error("Missing SUPABASE_SERVICE_ROLE_KEY in .env");
  process.exit(1);
}

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const OPENAI_MODEL = process.env.OPENAI_MODEL || "gpt-4o-mini";

// --------------------
// Utils
// --------------------

function parseModelJson(content) {
  try {
    return JSON.parse(content);
  } catch {
    const firstBrace = content.indexOf("{");
    const lastBrace = content.lastIndexOf("}");
    if (firstBrace === -1 || lastBrace === -1 || lastBrace <= firstBrace) {
      const err = new Error("Model returned non-JSON.");
      err.status = 502;
      err.raw = content;
      throw err;
    }
    const slice = content.slice(firstBrace, lastBrace + 1);
    try {
      return JSON.parse(slice);
    } catch {
      const err = new Error("Model returned invalid JSON.");
      err.status = 502;
      err.raw = content;
      throw err;
    }
  }
}

function sendError(res, err) {
  const status = err?.status ?? err?.statusCode ?? 500;
  const payload = { error: err?.message ?? "Unknown error" };
  if (err?.raw) payload.raw = err.raw;
  res.status(status).json(payload);
}

// --------------------
// Health check
// --------------------

app.get("/health", (_, res) => {
  res.json({ ok: true });
});

// --------------------
// PROD: /analysis
// (Supabase ì—°ë™)
// --------------------

app.post("/analysis", async (req, res) => {
  try {
    const authHeader = req.headers.authorization;
    const user = await getUserFromAuthHeader(authHeader);

    const { roomId } = req.body ?? {};
    if (!roomId) return res.status(400).json({ error: "roomId required" });

    const { votes } = await loadUserVotes(roomId, user.id);
    if (!votes || votes.length === 0) {
      return res.status(400).json({ error: "No votes found for user" });
    }

    // ðŸ”¥ prompt.jsì— ì‹œë‚˜ë¦¬ì˜¤/ë¬¸í•­ ë‚´ìž¥
    const prompt = buildPrompt(votes);

    const completion = await openai.chat.completions.create({
      model: OPENAI_MODEL,
      temperature: 0.25,
      messages: [
        {
          role: "system",
          content:
            "ë„ˆëŠ” ê°€ì¹˜/ì •ì¹˜ ì„±í–¥ ë¶„ì„ê°€ë‹¤. ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ë¼. JSONì˜ ëª¨ë“  ë¬¸ìžì—´ì€ í•œêµ­ì–´ë¡œ ìž‘ì„±í•˜ë¼."
        },
        { role: "user", content: prompt }
      ]
    });

    const content = completion?.choices?.[0]?.message?.content ?? "";
    const parsed = parseModelJson(content);

    res.json({
      roomId,
      userId: user.id,
      analysis: parsed
    });
  } catch (err) {
    console.error(err);
    sendError(res, err);
  }
});

// --------------------
// DEV: /analysis/dev
// (votesë§Œ ë°›ìŒ)
// --------------------

app.post("/analysis/dev", async (req, res) => {
  try {
    const { votes } = req.body ?? {};

    if (!votes || !Array.isArray(votes) || votes.length === 0) {
      return res.status(400).json({ error: "votes array required" });
    }

    // MOCK ëª¨ë“œ
    if (process.env.MOCK_ANALYSIS === "true") {
      return res.json({
        analysis: {
          ìµœì¢…_ë¼ë²¨: "í˜¼í•©í˜•(í…ŒìŠ¤íŠ¸)",
          ì‹ ë¢°ë„: 50,
          ìŠ¤íƒ¯: {
            ì§ˆì„œ: 60,
            ìžìœ : 40,
            ì„±ê³¼: 55,
            í‰ë“±: 45,
            ê³µë™ì²´: 50,
            ê°œì¸: 50
          },
          ê·¼ê±°: [
            { ë¬¸í•­: "Q1", ì„ íƒ: "A", ì„¤ëª…: "í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ê·¼ê±°ìž…ë‹ˆë‹¤." }
          ],
          ìš”ì•½: "ì´ ì‘ë‹µì€ MOCK_ANALYSIS=trueì¼ ë•Œ ë°˜í™˜ë˜ëŠ” í…ŒìŠ¤íŠ¸ìš© ê²°ê³¼ìž…ë‹ˆë‹¤."
        }
      });
    }

    const prompt = buildPrompt(votes);

    const completion = await openai.chat.completions.create({
      model: OPENAI_MODEL,
      temperature: 0.25,
      max_tokens: 800,
      frequency_penalty: 0.2,
      presence_penalty: 0.0,
      response_format: { type: "json_object" },
      messages: [
        {
          role: "system",
          content:
            "ë„ˆëŠ” ê°€ì¹˜/ì •ì¹˜ ì„±í–¥ ë¶„ì„ê°€ë‹¤. ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ë¼. JSONì˜ ëª¨ë“  ë¬¸ìžì—´ì€ í•œêµ­ì–´ë¡œ ìž‘ì„±í•˜ë¼."
        },
        { role: "user", content: prompt }
      ]
    });

    const content = completion?.choices?.[0]?.message?.content ?? "";
    const parsed = parseModelJson(content);

    res.json({ analysis: parsed });
  } catch (err) {
    console.error(err);
    sendError(res, err);
  }
});

// --------------------
// Server start
// --------------------

app.listen(PORT, () => {
  console.log(`AI analysis server running on port ${PORT}`);
});